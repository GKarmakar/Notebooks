{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "import utils2; importlib.reload(utils2)\n",
    "from utils2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "limit_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets.cifar10 import load_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are implementing densenet with cifar10 datasets based on paper by Huang et al.  densenet is simply resenet with replacing addition with concatenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Idea\n",
    "Recall that in broad terms, a Resnet is a Convnet that uses residual block structures.\n",
    "These \"blocks\" work as follows:\n",
    "Let Lt be the input layer to block\n",
    "Perform conv layer transformations/activations on Lt, denote by f(t)\n",
    "Call output layer of block Lt+1\n",
    "Define Lt+1 = f(Lt)+ Lt\n",
    "That is, total output is the conv layer outputs plus the original input\n",
    "We call residual block b.c. f(Lt)=Lt+1 - Lt, the residual\n",
    "As mentioned, the difference w/ DenseNet is instead of adding Lt to Lt+1, it is being concatenated.\n",
    "As with Resnet, DenseNet consists of multiple blocks. Therefore, there is a recursive relationship across blocks:\n",
    "Block Bi takes as input the ouput of block Bi-1 concatenated with the input of Bi-1\n",
    "The input to Bi-1 is the ouput of block Bi-2 concatenated with the input of Bi-2\n",
    "So on and so forth\n",
    "The number of filters added to each layer needs to be monitored, given that the input space for each block keeps growing.\n",
    "Huang et al. calls the # of filters added at each layer the growth rate, and appropriately denotes this num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    path = \"/users/trinakarmakar/anaconda2/data/cifar-10-batches-py\"\n",
    "    num_train_samples = 50000\n",
    "    x_train = np.zeros((num_train_samples, 3, 32, 32), dtype='uint8')\n",
    "    y_train = np.zeros((num_train_samples,), dtype='uint8')\n",
    "    for i in range(1, 6):\n",
    "        data, labels = load_batch(os.path.join(path, 'data_batch_' + str(i)))\n",
    "        x_train[(i - 1) * 10000: i * 10000, :, :, :] = data\n",
    "        y_train[(i - 1) * 10000: i * 10000] = labels  \n",
    "    x_test , y_test = load_batch(os.path.join(path, 'test_batch'))\n",
    "    y_train = np.reshape(y_train, (len(y_train), 1))\n",
    "    y_test = np.reshape(y_test, (len(y_test),1))\n",
    "    x_train = x_train.transpose(0, 2, 3, 1)\n",
    "    x_test = x_test.transpose(0, 2, 3, 1)\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12dfb7198>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFyKhKPiFSCj/D/EcoRMKOMsFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121237400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We wnat to normalize pixel values (0-255) to unit interval\n",
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(x): return Activation('relu')(x)\n",
    "def dropout(x, p): return Dropout(p)(x) if p else x\n",
    "def bn(x): return BatchNormalization(mode=0, axis=1)(x)\n",
    "def relu_bn(x): return relu(bn(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv(x, nf, sz, wd, p):\n",
    "    x = Convolution2D(nf, sz, sz, init='he_uniform', border_mode='same',\n",
    "                     W_regularizer=l2(wd))(x)\n",
    "    return dropout(x,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define ConvBlock as sequence:\n",
    "Batchnorm\n",
    "ReLU Activation\n",
    "Conv layer (conv w/ Dropout)\n",
    "The authors also use something called a bottleneck layer to reduce dimensionality of inputs.\n",
    "Recall that the filter space dimensionality grows at each block. The input dimensionality will determine the dimensionality of your convolution weight matrices, i.e. # of parameters.\n",
    "At size 3x3 or larger, convolutions can become extremely costly and # of parameters can increase quickly as a function of the input feature (filter) space. Therefore, a smart approach is to reduce dimensionality of filters by using a 1x1 convolution w/ smaller # of filters before the larger convolution.\n",
    "Bottleneck consists of:\n",
    "\n",
    "1x1 conv\n",
    "\n",
    "Compress # of filters into growth factor nf * 4\n",
    "\n",
    "Batchnorm -> ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_block(x, nf, bottleneck=False, p=None, wd=0):\n",
    "    x = relu_bn(x)\n",
    "    if bottleneck:\n",
    "        x = relu_bn(conv(x, nf * 4, 1, wd, p))\n",
    "    return conv(x, nf, 3, wd, p) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dense_block(x, nb_layers, growth_rate, bottleneck=False, p=None, wd=0):\n",
    "    if bottleneck:\n",
    "        nb_layers //=2\n",
    "    for i in range(nb_layers):\n",
    "        b = conv_block(x, growth_rate, bottleneck=bottleneck, p = p, wd=wd)\n",
    "        x = merge([x, b], mode='concat', concat_axis=-1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As typical for CV architectures, we'll do some pooling after computation.\n",
    "We'll define this unit as the transition block, and we'll put one between each dense block.\n",
    "Aside from BN -> ReLU and Average Pooling, there is also an option for filter compression in this block. This is simply feature reduction via 1x1 conv as discussed before, where the new # of filters is a percentage of the incoming # of filters.\n",
    "Together with bottleneck, compression has been shown to improve performance and computational efficiency of DenseNet architectures. (the authors call this DenseNet-BC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transition_block(x, compression=1.0, p = None, wd=0):\n",
    "    nf = int(x.get_shape().as_list()[-1] * compression)\n",
    "    x = relu_bn(x) \n",
    "    x = conv(x, nf, 1, wd, p)\n",
    "    return AveragePooling2D((2,2), strides=(2,2))(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the DenseNet model\n",
    "#### We've now defined all the building blocks (literally) to put together a DenseNet.\n",
    "nb_classes: number of classes\n",
    "img_input: tuple of shape (channels, rows, columns) or (rows, columns, channels)\n",
    "depth: total number of layers\n",
    "Includes 4 extra non-block layers\n",
    "1 input conv, 3 output layers\n",
    "nb_block: number of dense blocks (generally = 3).\n",
    "NOTE: Layers / block are evenly allocated. Therefore nb_block must be a factor of (Depth - 4)\n",
    "growth_rate: number of filters to add per dense block\n",
    "nb_filter: initial number of filters\n",
    "bottleneck: add bottleneck blocks\n",
    "Compression: Filter compression factor in transition blocks.\n",
    "p: dropout rate\n",
    "wd: weight decay\n",
    "activation: Type of activation at the top layer. Can be one of 'softmax' or 'sigmoid'. Note that if sigmoid is used, classes must be 1.\n",
    "\n",
    "Returns: keras tensor with nb_layers of conv_block appended\n",
    "From start to finish, this generates:\n",
    "Conv input layer\n",
    "Alternate between Dense/Transition blocks nb_block times, ommitting Transition block after last Dense block\n",
    "Each Dense block has (Depth-4)/nb_block layers\n",
    "Pass final Dense block to BN -> ReLU\n",
    "Global Avg Pooling\n",
    "Dense layer w/ desired output activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dense_net(nb_classes, img_output, depth=40, nb_block=3,\n",
    "                    growth_rate=12, nb_filter=16, bottleneck=False, compression=1.0,\n",
    "                    p = None, wd=0, activation='softmax'):\n",
    "    assert activation == 'softmax' or axtivation == 'sigmoid'\n",
    "    assert (depth - 4) % nb_block == 0\n",
    "    nb_layers_per_block = int((depth - 4) / nb_block)\n",
    "    nb_layers = [nb_layers_per_block] * nb_block\n",
    "    \n",
    "    x = conv(img_input, nb_filter, 3, wd, 0)\n",
    "    for i, block in enumerate(nb_layers):\n",
    "        x = dense_block(x, block, growth_rate, bottleneck=bottleneck, p=p, wd = wd)\n",
    "        if i != len(nb_layers) - 1:\n",
    "            x = dense_block(x, block, growth_rate, bottleneck=bottleneck, p=p, wd=wd)\n",
    "            if i != len(nb_layers)-1:\n",
    "                x = transition_block(x, compression=compression, p=p, wd=wd)\n",
    "            \n",
    "        \n",
    "    x = relu_bn(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    return Dense(nb_classes, activation=activation, W_regulaizer=l2(wd))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (32,32,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_input = Input(shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/trinakarmakar/anaconda2/envs/dl4nlp/lib/python3.5/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), kernel_regularizer=<keras.reg..., kernel_initializer=\"he_uniform\", padding=\"same\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/trinakarmakar/anaconda2/envs/dl4nlp/lib/python3.5/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(axis=1)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/trinakarmakar/anaconda2/envs/dl4nlp/lib/python3.5/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (1, 1), kernel_regularizer=<keras.reg..., kernel_initializer=\"he_uniform\", padding=\"same\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/trinakarmakar/anaconda2/envs/dl4nlp/lib/python3.5/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), kernel_regularizer=<keras.reg..., kernel_initializer=\"he_uniform\", padding=\"same\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/trinakarmakar/anaconda2/envs/dl4nlp/lib/python3.5/site-packages/ipykernel_launcher.py:6: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  \n",
      "/Users/trinakarmakar/anaconda2/envs/dl4nlp/lib/python3.5/site-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/Users/trinakarmakar/anaconda2/envs/dl4nlp/lib/python3.5/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(200, (1, 1), kernel_regularizer=<keras.reg..., kernel_initializer=\"he_uniform\", padding=\"same\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/trinakarmakar/anaconda2/envs/dl4nlp/lib/python3.5/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(292, (1, 1), kernel_regularizer=<keras.reg..., kernel_initializer=\"he_uniform\", padding=\"same\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "('Keyword argument not understood:', 'W_regulaizer')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e62d76cd50f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m x = create_dense_net(10, img_input, depth=100, nb_filter=16,\n\u001b[0;32m----> 2\u001b[0;31m                     compression=0.5, bottleneck=True, wd=1e-4)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-1c78927e058b>\u001b[0m in \u001b[0;36mcreate_dense_net\u001b[0;34m(nb_classes, img_output, depth, nb_block, growth_rate, nb_filter, bottleneck, compression, p, wd, activation)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelu_bn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGlobalAveragePooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW_regulaizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/dl4nlp/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/dl4nlp/lib/python3.5/site-packages/keras/layers/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'input_shape'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'input_dim'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_shape'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input_dim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/dl4nlp/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Keyword argument not understood:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ('Keyword argument not understood:', 'W_regulaizer')"
     ]
    }
   ],
   "source": [
    "x = create_dense_net(10, img_input, depth=100, nb_filter=16,\n",
    "                    compression=0.5, bottleneck=True, wd=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(img_input)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "dl4nlp",
   "language": "python",
   "name": "dl4nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
